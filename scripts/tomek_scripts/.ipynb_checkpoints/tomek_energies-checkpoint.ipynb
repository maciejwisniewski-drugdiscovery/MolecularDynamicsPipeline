{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f074584-95ee-4b89-999b-de451842d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import biotite.structure as struc\n",
    "import biotite.structure.io as bsio\n",
    "import biotite.structure.io.pdb as pdb\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.structure.io.xtc as xtc\n",
    "from biotite.interface import openmm as biotite_openmm\n",
    "\n",
    "import openmm\n",
    "from openmm import *\n",
    "from openmm.app import *\n",
    "from openmm.unit import *\n",
    "from openmm import XmlSerializer\n",
    "\n",
    "from openmm import LangevinIntegrator, Context, Platform\n",
    "from openmm import Platform, XmlSerializer, LangevinIntegrator, NonbondedForce, CustomExternalForce, MonteCarloBarostat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf03a65b-6cda-478f-b3a4-421b3d6dceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import biotite.structure as struc\n",
    "import biotite.structure.io as bsio\n",
    "import biotite.structure.io.pdb as pdb\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.structure.io.xtc as xtc\n",
    "from biotite.interface import openmm as biotite_openmm\n",
    "\n",
    "import openmm\n",
    "from openmm import *\n",
    "from openmm.app import *\n",
    "from openmm.unit import *\n",
    "from openmm import XmlSerializer\n",
    "\n",
    "from openmm import LangevinIntegrator, Context, Platform\n",
    "from openmm import Platform, XmlSerializer, LangevinIntegrator, NonbondedForce, CustomExternalForce, MonteCarloBarostat\n",
    "\n",
    "\n",
    "def create_subset_topology(topology: Topology, atom_indices: List[int]) -> Topology:\n",
    "    \"\"\"\n",
    "    Create a new OpenMM Topology object containing only a subset of atoms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    topology : openmm.app.Topology\n",
    "        The original topology.\n",
    "    atom_indices : list of int\n",
    "        A list of atom indices to include in the new topology.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    openmm.app.Topology\n",
    "        A new topology containing only the specified atoms, their residues,\n",
    "        chains, and the bonds between them.\n",
    "    \"\"\"\n",
    "    new_top = Topology()\n",
    "    old_to_new_atoms = {}\n",
    "    indices_set = set(atom_indices)\n",
    "    \n",
    "    # Create new chains, residues, and atoms\n",
    "    for chain in topology.chains():\n",
    "        new_chain = new_top.addChain(chain.id)\n",
    "        for residue in chain.residues():\n",
    "            residue_atoms = list(residue.atoms())\n",
    "            # Check if any atom from this residue is in our subset\n",
    "            if any(atom.index in indices_set for atom in residue_atoms):\n",
    "                new_res = new_top.addResidue(residue.name, new_chain, residue.id)\n",
    "                # Add atoms that are in our subset\n",
    "                for atom in residue_atoms:\n",
    "                    if atom.index in indices_set:\n",
    "                        new_atom = new_top.addAtom(atom.name, atom.element, new_res, atom.id)\n",
    "                        old_to_new_atoms[atom] = new_atom\n",
    "    \n",
    "    # Create new bonds between atoms that are both in the subset\n",
    "    for bond in topology.bonds():\n",
    "        atom1, atom2 = bond\n",
    "        if atom1 in old_to_new_atoms and atom2 in old_to_new_atoms:\n",
    "            new_top.addBond(old_to_new_atoms[atom1], old_to_new_atoms[atom2])\n",
    "    \n",
    "    return new_top\n",
    "\n",
    "\n",
    "def split_molecular_dynamics_into_components(topology_filepath: Path,\n",
    "    trajectory_filepath: Path,\n",
    "    output_dir: Path,\n",
    "    renamed_chains: Optional[List[str]] = None):\n",
    "    \"\"\"\n",
    "    Split a molecular dynamics trajectory into components using OpenMM for topology\n",
    "    manipulation and biotite for coordinate handling.\n",
    "    \n",
    "    Note: trajectory_filepath should be an .xtc file containing a subset of atoms (proteins and ligands).\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    single_output_dir = output_dir / 'single'\n",
    "    single_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    pair_output_dir = output_dir / 'pair'\n",
    "    pair_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load topology and positions with OpenMM\n",
    "    openmm_cif = PDBxFile(str(topology_filepath))\n",
    "    full_openmm_topology = openmm_cif.getTopology()\n",
    "    full_openmm_positions = openmm_cif.getPositions(asNumpy=True)\n",
    "\n",
    "    # Load trajectory from .xtc file\n",
    "    xtc_file = xtc.XTCFile.read(str(trajectory_filepath))\n",
    "    all_coords = xtc_file.get_coord()\n",
    "\n",
    "    # Load structure with Biotite for chain information\n",
    "    biotite_cif = pdbx.CIFFile.read(topology_filepath)\n",
    "    full_biotite_structure = pdbx.get_structure(biotite_cif, model=1, include_bonds=True)\n",
    "    \n",
    "    # Filter topology and positions to match trajectory atoms\n",
    "    # The XTC file contains only a subset of atoms (proteins and ligands without water/ions)\n",
    "    excluded_residues = {'HOH', 'WAT', 'TIP3', 'TIP4', 'TIP5', 'SPC', 'SPCE', 'CL', 'NA'}\n",
    "    \n",
    "    # Create atom mask to match what was saved in XTC\n",
    "    trajectory_mask = np.ones(full_biotite_structure.array_length(), dtype=bool)\n",
    "    for i, residue_name in enumerate(full_biotite_structure.res_name):\n",
    "        if residue_name in excluded_residues:\n",
    "            trajectory_mask[i] = False\n",
    "    \n",
    "    # Filter to match trajectory\n",
    "    solute_biotite_structure = full_biotite_structure[trajectory_mask]\n",
    "    solute_openmm_topology = biotite_openmm.to_topology(solute_biotite_structure)\n",
    "    #solute_openmm_topology = create_subset_topology(full_openmm_topology, np.where(trajectory_mask)[0].tolist())\n",
    "    solute_openmm_positions = full_openmm_positions[trajectory_mask]\n",
    "    solute_coords = all_coords\n",
    "\n",
    "    # Verify coordinate dimensions match topology\n",
    "    n_atoms_topology = solute_biotite_structure.array_length()\n",
    "    n_atoms_trajectory = solute_coords.shape[1]\n",
    "    \n",
    "    if n_atoms_topology != n_atoms_trajectory:\n",
    "        print(f\"Warning: Topology has {n_atoms_topology} atoms but trajectory has {n_atoms_trajectory} atoms\")\n",
    "        print(\"Attempting to match trajectory dimensions by adjusting atom selection...\")\n",
    "        \n",
    "        # If dimensions don't match, try to find the correct subset\n",
    "        # This is a fallback that assumes the trajectory was created with specific filtering\n",
    "        if n_atoms_trajectory < n_atoms_topology:\n",
    "            # Try to trim topology to match trajectory\n",
    "            solute_biotite_structure = solute_biotite_structure[:n_atoms_trajectory]\n",
    "            trajectory_indices = np.where(trajectory_mask)[0][:n_atoms_trajectory]\n",
    "            solute_openmm_topology = create_subset_topology(full_openmm_topology, trajectory_indices.tolist())\n",
    "            solute_openmm_positions = full_openmm_positions[trajectory_indices]\n",
    "            \n",
    "            print(f\"Adjusted topology to match trajectory: {n_atoms_trajectory} atoms\")\n",
    "        else:\n",
    "            raise ValueError(f\"Trajectory has more atoms ({n_atoms_trajectory}) than available in topology ({n_atoms_topology})\")\n",
    "\n",
    "    chain_ids = np.unique(solute_biotite_structure.chain_id)\n",
    "\n",
    "    all_tqdm_bar = tqdm(total=len(chain_ids) + len(list(itertools.combinations(chain_ids, 2))),\n",
    "                        desc='Splitting Trajectory')\n",
    "\n",
    "    # Generate Single Component Topologies and Trajectories\n",
    "    for chain_id in chain_ids:\n",
    "        component_topology_filename = single_output_dir / f'{chain_id}.cif'\n",
    "        component_trajectory_filename = single_output_dir / f'{chain_id}.xtc'\n",
    "\n",
    "        chain_mask = (solute_biotite_structure.chain_id == chain_id)\n",
    "        component_indices = np.where(chain_mask)[0].tolist()\n",
    "        \n",
    "        component_topology = create_subset_topology(solute_openmm_topology, component_indices)\n",
    "        component_positions = solute_openmm_positions[chain_mask]\n",
    "        component_coords = solute_coords[:, chain_mask, :]\n",
    "\n",
    "        with open(str(component_topology_filename), 'w') as f:\n",
    "            PDBxFile.writeFile(component_topology, component_positions, f, keepIds=True)\n",
    "\n",
    "        # Save trajectory as .xtc file\n",
    "        xtc_file = xtc.XTCFile()\n",
    "        xtc_file.set_coord(component_coords)\n",
    "        xtc_file.write(str(component_trajectory_filename))\n",
    "\n",
    "        all_tqdm_bar.update(1)\n",
    "\n",
    "    # Generate Paired Component Topologies and Trajectories\n",
    "    for chain_id_a, chain_id_b in itertools.combinations(chain_ids, 2):\n",
    "        component_topology_filename = pair_output_dir / f'{chain_id_a}_{chain_id_b}.cif'\n",
    "        component_trajectory_filename = pair_output_dir / f'{chain_id_a}_{chain_id_b}.xtc'\n",
    "        \n",
    "        chain_a_mask = (solute_biotite_structure.chain_id == chain_id_a)\n",
    "        chain_b_mask = (solute_biotite_structure.chain_id == chain_id_b)\n",
    "        component_mask = chain_a_mask | chain_b_mask\n",
    "        component_indices = np.where(component_mask)[0].tolist()\n",
    "\n",
    "        component_topology = create_subset_topology(solute_openmm_topology, component_indices)\n",
    "        component_positions = solute_openmm_positions[component_mask]\n",
    "        component_coords = solute_coords[:, component_mask, :]\n",
    "\n",
    "        with open(str(component_topology_filename), 'w') as f:\n",
    "            PDBxFile.writeFile(component_topology, component_positions, f, keepIds=True)\n",
    "\n",
    "        # Save trajectory as .xtc file\n",
    "        xtc_file = xtc.XTCFile()\n",
    "        xtc_file.set_coord(component_coords)\n",
    "        xtc_file.write(str(component_trajectory_filename))\n",
    "\n",
    "        all_tqdm_bar.update(1)\n",
    "\n",
    "    all_tqdm_bar.close()\n",
    "\n",
    "\n",
    "def calculate_component_energy(component_topology_filepath: Path, \n",
    "                                component_trajectory_filepath: Path,\n",
    "                                forcefield_filepath: Path) -> List[float]:\n",
    "    \"\"\"\n",
    "    Calculate the potential energy for each frame of a component's trajectory.\n",
    "    \"\"\"\n",
    "    component_name = component_topology_filepath.stem\n",
    "    \n",
    "    # Load topology reference coordinates\n",
    "    component_topology_file = pdbx.CIFFile.read(component_topology_filepath)\n",
    "    component_topology_coords = pdbx.get_structure(component_topology_file, model=1, include_bonds=True).coord\n",
    "\n",
    "    # Load OpenMM topology\n",
    "    component_topology = PDBxFile(str(component_topology_filepath)).topology\n",
    "    \n",
    "    # Load trajectory from .xtc file\n",
    "    xtc_file = xtc.XTCFile.read(str(component_trajectory_filepath))\n",
    "    coords = xtc_file.get_coord()\n",
    "\n",
    "    # Combine topology coordinates with trajectory coordinates\n",
    "    all_coords = np.concatenate([component_topology_coords[None, ...], coords], axis=0)\n",
    "\n",
    "    # Setup forcefield\n",
    "    with open(forcefield_filepath, 'rb') as f:\n",
    "        forcefield = pickle.load(f)\n",
    "\n",
    "    # For vacuum calculations, NoCutoff is appropriate\n",
    "    system = forcefield.createSystem(component_topology, nonbondedMethod=NoCutoff)\n",
    "    # Integrator settings don't matter much as we are not running dynamics\n",
    "    integrator = LangevinIntegrator(300*kelvin, 1/picosecond, 0.002*picoseconds)\n",
    "    platform = Platform.getPlatformByName('CUDA')\n",
    "    simulation = Simulation(component_topology, system, integrator, platform)\n",
    "\n",
    "    energies = []\n",
    "    for frame in tqdm(all_coords, desc=f'Processing {component_name} energies', leave=False):\n",
    "        simulation.context.setPositions(frame)\n",
    "        state = simulation.context.getState(getEnergy=True)\n",
    "        energy = state.getPotentialEnergy().value_in_unit(kilojoule_per_mole)\n",
    "        energies.append(energy)\n",
    "\n",
    "    return energies\n",
    "\n",
    "\n",
    "def calculate_interaction_energies(\n",
    "    topology_filepath: Path,\n",
    "    trajectory_filepath: Path,\n",
    "    forcefield_filepath: Path,\n",
    "    output_dir: Path,\n",
    "    stage: str = \"production\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Orchestrates splitting a trajectory, calculating energies for all components,\n",
    "    and computing an MMPBSA-like interaction matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    topology_filepath : Path\n",
    "        Path to the topology file.\n",
    "    trajectory_filepath : Path\n",
    "        Path to the trajectory file (XTC format).\n",
    "    forcefield_dirpath : Path\n",
    "        Path to the forcefield directory.\n",
    "    output_dir : Path\n",
    "        Path to the output directory.\n",
    "    stage : str\n",
    "        The simulation stage name (e.g., 'nvt', 'npt', 'production').\n",
    "    \"\"\"\n",
    "    # 1. Split trajectory into components\n",
    "    split_dir = output_dir / 'components'\n",
    "    split_molecular_dynamics_into_components(\n",
    "        topology_filepath=topology_filepath,\n",
    "        trajectory_filepath=trajectory_filepath,\n",
    "        output_dir=split_dir\n",
    "    )\n",
    "\n",
    "    # 2. Calculate energies for all components\n",
    "    all_energies = {}\n",
    "    \n",
    "    single_component_dir = split_dir / 'single'\n",
    "    pair_component_dir = split_dir / 'pair'\n",
    "\n",
    "    single_topologies = sorted(list(single_component_dir.glob('*.cif')))\n",
    "    pair_topologies = sorted(list(pair_component_dir.glob('*.cif')))\n",
    "\n",
    "    all_topologies = single_topologies + pair_topologies\n",
    "    \n",
    "    print(\"Calculating energies for all components...\")\n",
    "    for top_file in tqdm(all_topologies, desc=\"Overall Progress\"):\n",
    "        component_name = top_file.stem\n",
    "        traj_file = top_file.with_suffix('.xtc')\n",
    "        \n",
    "        # Check if trajectory file exists\n",
    "        if not traj_file.exists():\n",
    "            print(f\"Warning: Trajectory file not found: {traj_file}\")\n",
    "            continue\n",
    "            \n",
    "        energies = calculate_component_energy(\n",
    "            component_topology_filepath=top_file,\n",
    "            component_trajectory_filepath=traj_file,\n",
    "            forcefield_filepath=forcefield_filepath\n",
    "        )\n",
    "        all_energies[component_name] = energies\n",
    "\n",
    "    # 3. Create JSON output with stage-specific name\n",
    "    json_output_list = []\n",
    "    for name, energy_list in all_energies.items():\n",
    "        components = name.split('_')\n",
    "        json_output_list.append({\n",
    "            'components': components,\n",
    "            'energies': energy_list\n",
    "        })\n",
    "    \n",
    "    json_filepath = output_dir / f'{stage}_component_energies.json'\n",
    "    print(f\"Saving component energies to {json_filepath}\")\n",
    "    with open(json_filepath, 'w') as f:\n",
    "        json.dump(json_output_list, f, indent=2)\n",
    "\n",
    "    # 4. Create and save the N x N x Frames interaction energy matrix.\n",
    "    single_component_names = [p.stem for p in single_topologies]\n",
    "    if not single_component_names:\n",
    "        print(\"No single components found. Skipping matrix generation.\")\n",
    "        print(\"Energy calculation finished.\")\n",
    "        return\n",
    "\n",
    "    N = len(single_component_names)\n",
    "    # Get number of frames from the first component's energy list\n",
    "    F = len(next(iter(all_energies.values())))\n",
    "\n",
    "    # Create a mapping from component name to matrix index\n",
    "    component_to_idx = {name: i for i, name in enumerate(single_component_names)}\n",
    "\n",
    "    # Initialize the 3D matrix for all-vs-all interaction energies\n",
    "    interaction_matrix_3d = np.zeros((N, N, F), dtype=float)\n",
    "\n",
    "    # Convert all energy lists to numpy arrays for vectorized operations\n",
    "    energies_np = {name: np.array(energy_list) for name, energy_list in all_energies.items()}\n",
    "\n",
    "    # Iterate over unique pairs of components to calculate interaction energies\n",
    "    for r_name, c_name in itertools.combinations(single_component_names, 2):\n",
    "        r_idx = component_to_idx[r_name]\n",
    "        c_idx = component_to_idx[c_name]\n",
    "        \n",
    "        # Find the energy time-series for the pair complex\n",
    "        pair_name_1 = f\"{r_name}_{c_name}\"\n",
    "        pair_name_2 = f\"{c_name}_{r_name}\"\n",
    "        \n",
    "        if pair_name_1 in energies_np:\n",
    "            pair_energy_ts = energies_np[pair_name_1]\n",
    "        elif pair_name_2 in energies_np:\n",
    "            pair_energy_ts = energies_np[pair_name_2]\n",
    "        else:\n",
    "            print(f\"Warning: Pair energy time series for {r_name} and {c_name} not found. Skipping this pair.\")\n",
    "            continue\n",
    "            \n",
    "        # Calculate interaction energy for all frames at once (vectorized)\n",
    "        interaction_energy_ts = pair_energy_ts - (energies_np[r_name] + energies_np[c_name])\n",
    "        \n",
    "        # Populate the symmetric matrix\n",
    "        interaction_matrix_3d[r_idx, c_idx, :] = interaction_energy_ts\n",
    "        interaction_matrix_3d[c_idx, r_idx, :] = interaction_energy_ts\n",
    "\n",
    "    # Save the 3D matrix and component labels to a single .npz file with stage-specific name\n",
    "    matrix_filepath = output_dir / f'{stage}_interaction_energy_matrix.npz'\n",
    "    print(f\"Saving {N}x{N}x{F} interaction energy matrix to {matrix_filepath}\")\n",
    "    np.savez(\n",
    "        matrix_filepath,\n",
    "        matrix=interaction_matrix_3d,\n",
    "        components=np.array(single_component_names)\n",
    "    )\n",
    "\n",
    "    # 5. Cleanup temporary component files\n",
    "    print(\"Cleaning up temporary component files...\")\n",
    "    cleanup_temporary_files(split_dir)\n",
    "\n",
    "    print(\"Energy calculation finished.\")\n",
    "\n",
    "\n",
    "def cleanup_temporary_files(components_dir: Path):\n",
    "    \"\"\"\n",
    "    Clean up temporary component files created during energy calculation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    components_dir : Path\n",
    "        Path to the components dirsectory containing temporary files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import shutil\n",
    "        if components_dir.exists():\n",
    "            shutil.rmtree(components_dir)\n",
    "            print(f\"Removed temporary component directory: {components_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not remove temporary files: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441c912c-9c3f-4119-bad1-af8b66e9856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dirpath = Path('/mnt/evafs/groups/sfglab/mwisniewski/data/tomasz_md/md')\n",
    "output_dirpath = Path('/mnt/evafs/groups/sfglab/mwisniewski/data/tomasz_md/md/4EKL__4EKL__26__dock_simulation_bound_state')\n",
    "topology_path = output_dirpath / '4EKL__4EKL__26__dock_init_topology.cif'\n",
    "trajectory_path = output_dirpath / 'trajectories' / '4EKL__4EKL__26__dock_production_trajectory.xtc'\n",
    "forcefield_dirpath = output_dirpath / 'forcefields' / 'system_forcefield.pkl'\n",
    "energy_output_dirpath = output_dirpath / 'energies'\n",
    "\n",
    "energy_output_dirpath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95fb9e-fe18-4f75-9320-04b3a49c3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = calculate_component_energy(\n",
    "    component_topology_filepath=Path('/mnt/evafs/groups/sfglab/mwisniewski/data/tomasz_md/md/4EKL__4EKL__26__dock_simulation_bound_state/energies/components/single/4EKL__26__dock.cif'),\n",
    "    component_trajectory_filepath=Path('/mnt/evafs/groups/sfglab/mwisniewski/data/tomasz_md/md/4EKL__4EKL__26__dock_simulation_bound_state/energies/components/single/4EKL__26__dock.xtc'),\n",
    "    forcefield_filepath=forcefield_dirpath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c8ebb-5d79-433d-9651-7c1f30f22b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
